{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "installing nltk package so that if it is not previosly installed we will install it in first process itself"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: nltk in /home/ghansham/.local/lib/python3.8/site-packages (3.7)\n",
      "Requirement already satisfied: tqdm in /home/ghansham/.local/lib/python3.8/site-packages (from nltk) (4.64.0)\n",
      "Requirement already satisfied: click in /usr/lib/python3/dist-packages (from nltk) (7.0)\n",
      "Requirement already satisfied: regex>=2021.8.3 in /home/ghansham/.local/lib/python3.8/site-packages (from nltk) (2022.7.25)\n",
      "Requirement already satisfied: joblib in /home/ghansham/.local/lib/python3.8/site-packages (from nltk) (1.1.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package brown to /home/ghansham/nltk_data...\n",
      "[nltk_data]   Package brown is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# so as we successfulley installed the nltk package we will download a package called brown\n",
    "# inside it\n",
    "import nltk\n",
    "nltk.download(\"brown\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['adventure',\n",
       " 'belles_lettres',\n",
       " 'editorial',\n",
       " 'fiction',\n",
       " 'government',\n",
       " 'hobbies',\n",
       " 'humor',\n",
       " 'learned',\n",
       " 'lore',\n",
       " 'mystery',\n",
       " 'news',\n",
       " 'religion',\n",
       " 'reviews',\n",
       " 'romance',\n",
       " 'science_fiction']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# now we will see the all catagories inside from the brown \n",
    "from nltk.corpus import brown\n",
    "brown.categories()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['The', 'Fulton', 'County', 'Grand', 'Jury', 'said', 'Friday', 'an', 'investigation', 'of', \"Atlanta's\", 'recent', 'primary', 'election', 'produced', '``', 'no', 'evidence', \"''\", 'that', 'any', 'irregularities', 'took', 'place', '.'], ['The', 'jury', 'further', 'said', 'in', 'term-end', 'presentments', 'that', 'the', 'City', 'Executive', 'Committee', ',', 'which', 'had', 'over-all', 'charge', 'of', 'the', 'election', ',', '``', 'deserves', 'the', 'praise', 'and', 'thanks', 'of', 'the', 'City', 'of', 'Atlanta', \"''\", 'for', 'the', 'manner', 'in', 'which', 'the', 'election', 'was', 'conducted', '.'], ...]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# showing the sents from the brown subpackage \n",
    "# it will return a 2d array \n",
    "brown.sents()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /home/ghansham/nltk_data...\n",
      "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# now the original game of tokenization will start \n",
    "import nltk\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Hello', '!', 'Ghansham', 'Salunkhe', 'here', '.', 'I', \"'m\", 'student', 'of', 'COEP', 'and', 'I', 'live', 'in', 'Sankalp', 'Society', ',', 'Shivajinagar', '.']\n"
     ]
    }
   ],
   "source": [
    "# so for your info tokenizer are present inside nltk.tokenize \n",
    "# from nltk.tokenize you can get word_tokenize and other tokenizers \n",
    "# on basis of spaces and on basis of spaces tokens are getting created\n",
    "from nltk import word_tokenize\n",
    "a=\"Hello! Ghansham Salunkhe here. I'm  student of COEP and I live in Sankalp Society, Shivajinagar.\"\n",
    "print(word_tokenize(a))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Hello!', 'Ghansham Salunkhe here.', \"I'm  student of COEP and I live in Sankalp Society, Shivajinagar.\"]\n"
     ]
    }
   ],
   "source": [
    "# sent sent_tokenize is used in order to break a text  on basis of punctuation marks like ! . \n",
    "from nltk import sent_tokenize\n",
    "a=\"Hello! Ghansham Salunkhe here. I'm  student of COEP and I live in Sankalp Society, Shivajinagar.\"\n",
    "print(sent_tokenize(a))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['John Felix Anthony Cena (/ˈsiːnə/ SEE-nə; born April 23, 1977) is an American professional wrestler, actor, and     former rapper, currently signed to WWE.', 'Widely regarded as one of the greatest professional wrestlers of all time,     he is tied with Ric Flair for the most world championship reigns in professional wrestling history.', '[a]    Born in West Newbury, Massachusetts, Cena moved to California in 1998 to pursue a career as a bodybuilder.', 'He switched to professional wrestling in 1999 when he debuted for Ultimate Pro Wrestling.', 'He signed with     the World Wrestling Federation (WWF, now WWE) in 2001, where he was assigned to Ohio Valley Wrestling.', \"After moving to WWE's SmackDown roster in 2002, Cena gained fame and success after adopting the     persona of a trash-talking rapper.\", 'He won his first singles title, the United States Championship']\n",
      "7\n",
      "6\n"
     ]
    }
   ],
   "source": [
    "# sent_tokenize on large text \n",
    "from nltk.tokenize import sent_tokenize\n",
    "a=\"John Felix Anthony Cena (/ˈsiːnə/ SEE-nə; born April 23, 1977) is an American professional wrestler, actor, and \\\n",
    "    former rapper, currently signed to WWE. Widely regarded as one of the greatest professional wrestlers of all time, \\\n",
    "    he is tied with Ric Flair for the most world championship reigns in professional wrestling history.[a]\\\n",
    "    Born in West Newbury, Massachusetts, Cena moved to California in 1998 to pursue a career as a bodybuilder.\\\n",
    "    He switched to professional wrestling in 1999 when he debuted for Ultimate Pro Wrestling. He signed with \\\n",
    "    the World Wrestling Federation (WWF, now WWE) in 2001, where he was assigned to Ohio Valley Wrestling.\\\n",
    "    After moving to WWE's SmackDown roster in 2002, Cena gained fame and success after adopting the \\\n",
    "    persona of a trash-talking rapper. He won his first singles title, the United States Championship\" \n",
    "\n",
    "print(sent_tokenize(a))\n",
    "print(len(sent_tokenize(a)))\n",
    "# if full stops are 6 so sentense must be 7(6+1)\n",
    "print(a.count('.'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentence, : sentenc\n",
      "Stems, : stem\n",
      "or, : or\n",
      "Sentence, : sentenc\n",
      "Frames, : frame\n",
      "Picture, : pictur\n",
      "WHAT, : what\n",
      "IS, : is\n",
      "THE, : the\n",
      "DIFFERENCE, : differ\n",
      "AND, : and\n",
      "WHY, : whi\n",
      "SHOULD, : should\n",
      "WE, : we\n",
      "CARE, : care\n",
      "?, : ?\n",
      "Well, : well\n",
      ",, : ,\n",
      "first, : first\n",
      "and, : and\n",
      "foremost, : foremost\n",
      ",, : ,\n",
      "we, : we\n",
      "should, : should\n",
      "care, : care\n",
      "if, : if\n",
      "we, : we\n",
      "want, : want\n",
      "our, : our\n",
      "students, : student\n",
      "to, : to\n",
      "speak, : speak\n",
      "like, : like\n",
      "scholars, : scholar\n",
      "., : .\n",
      "If, : if\n",
      "we, : we\n",
      "want, : want\n",
      "our, : our\n",
      "students, : student\n",
      "to, : to\n",
      "be, : be\n",
      "marketable, : market\n",
      "after, : after\n",
      "they, : they\n",
      "graduate, : graduat\n",
      "., : .\n",
      "If, : if\n",
      "we, : we\n",
      "want, : want\n",
      "them, : them\n",
      "TO, : to\n",
      "graduate, : graduat\n",
      "!, : !\n",
      "Then, : then\n",
      "we, : we\n",
      "should, : should\n",
      "care, : care\n",
      "!, : !\n",
      "Sentence, : sentenc\n",
      "stems, : stem\n",
      "and, : and\n",
      "frames, : frame\n",
      "are, : are\n",
      "scaffolds, : scaffold\n",
      "as, : as\n",
      "students, : student\n",
      "learn, : learn\n",
      "language, : languag\n",
      "and, : and\n",
      "content, : content\n",
      "., : .\n",
      "Sometimes, : sometim\n",
      "educators, : educ\n",
      "use, : use\n",
      "the, : the\n",
      "terms, : term\n",
      "sentence, : sentenc\n",
      "stems, : stem\n",
      ",, : ,\n",
      "sentence, : sentenc\n",
      "starters, : starter\n",
      "and, : and\n",
      "sentence, : sentenc\n",
      "frames, : frame\n",
      "interchangeably.You, : interchangeably.y\n",
      "may, : may\n",
      "wonder, : wonder\n",
      "..., : ...\n",
      "are, : are\n",
      "they, : they\n",
      "the, : the\n",
      "same, : same\n",
      "thing, : thing\n",
      "?, : ?\n",
      "The, : the\n",
      "answer, : answer\n",
      "is, : is\n",
      "no, : no\n",
      ",, : ,\n",
      "they, : they\n",
      "are, : are\n",
      "are, : are\n",
      "not, : not\n",
      "the, : the\n",
      "same, : same\n",
      "., : .\n",
      "They, : they\n",
      "have, : have\n",
      "their, : their\n",
      "own, : own\n",
      "form, : form\n",
      "and, : and\n",
      "function, : function\n",
      "., : .\n",
      "Sentence, : sentenc\n",
      "Frames, : frame\n",
      "Sentence, : sentenc\n",
      "frames, : frame\n",
      "essentially, : essenti\n",
      "frame, : frame\n",
      "a, : a\n",
      "sentence, : sentenc\n",
      "and, : and\n",
      "students, : student\n",
      "add, : add\n",
      "in, : in\n",
      "some, : some\n",
      "verbiage, : verbiag\n",
      "., : .\n",
      "Think, : think\n",
      "of, : of\n",
      "a, : a\n",
      "picture, : pictur\n",
      "frame, : frame\n",
      "where, : where\n",
      "you, : you\n",
      "add, : add\n",
      "in, : in\n",
      "a, : a\n",
      "picture, : pictur\n",
      "., : .\n",
      "Sentence, : sentenc\n",
      "frames, : frame\n",
      "look, : look\n",
      "very, : veri\n",
      "much, : much\n",
      "like, : like\n",
      "traditional, : tradit\n",
      "fill, : fill\n",
      "in, : in\n",
      "the, : the\n",
      "blank, : blank\n",
      "sentences, : sentenc\n",
      "., : .\n",
      "Here, : here\n",
      "are, : are\n",
      "some, : some\n",
      "examples, : exampl\n",
      "of, : of\n",
      "sentence, : sentenc\n",
      "frames, : frame\n",
      ":, : :\n",
      "Sentence, : sentenc\n",
      "frames, : frame\n",
      "are, : are\n",
      "scaffolds, : scaffold\n",
      "that, : that\n",
      "may, : may\n",
      "fit, : fit\n",
      "the, : the\n",
      "needs, : need\n",
      "of, : of\n",
      "English, : english\n",
      "learners, : learner\n",
      "at, : at\n",
      "beginning, : begin\n",
      "levels, : level\n",
      "of, : of\n",
      "English, : english\n",
      "proficiency, : profici\n",
      "., : .\n",
      "Some, : some\n",
      "students, : student\n",
      "may, : may\n",
      "also, : also\n",
      "benefit, : benefit\n",
      "from, : from\n",
      "visuals, : visual\n",
      "and, : and\n",
      "word, : word\n",
      "banks, : bank\n",
      "., : .\n",
      "However, : howev\n",
      ",, : ,\n",
      "sentence, : sentenc\n",
      "frames, : frame\n",
      "can, : can\n",
      "be, : be\n",
      "used, : use\n",
      "with, : with\n",
      "English, : english\n",
      "learners, : learner\n",
      "at, : at\n",
      "higher, : higher\n",
      "levels, : level\n",
      "of, : of\n",
      "English, : english\n",
      "proficiency, : profici\n",
      "to, : to\n",
      "teach, : teach\n",
      "specific, : specif\n",
      "language, : languag\n",
      "structures, : structur\n",
      "or, : or\n",
      "to, : to\n",
      "teach, : teach\n",
      "mortar, : mortar\n",
      "words/tier, : words/tier\n",
      "II, : ii\n",
      "words.A, : words.a\n",
      "sentence, : sentenc\n",
      "stem, : stem\n",
      "is, : is\n",
      "the, : the\n",
      "beginning, : begin\n",
      "of, : of\n",
      "a, : a\n",
      "sentence, : sentenc\n",
      "., : .\n",
      "Think, : think\n",
      "of, : of\n",
      "the, : the\n",
      "stem, : stem\n",
      "of, : of\n",
      "a, : a\n",
      "plant, : plant\n",
      "., : .\n",
      "It, : it\n",
      "'s, : 's\n",
      "not, : not\n",
      "the, : the\n",
      "whole, : whole\n",
      "plant, : plant\n",
      ",, : ,\n",
      "just, : just\n",
      "the, : the\n",
      "beginning, : begin\n",
      "of, : of\n",
      "it, : it\n",
      "., : .\n",
      "It, : it\n",
      "helps, : help\n",
      "students, : student\n",
      "get, : get\n",
      "their, : their\n",
      "sentence, : sentenc\n",
      "started, : start\n",
      "., : .\n",
      "Sometimes, : sometim\n",
      "we, : we\n",
      "use, : use\n",
      "the, : the\n",
      "term, : term\n",
      "sentence, : sentenc\n",
      "starter, : starter\n",
      "interchangeably, : interchang\n",
      "., : .\n",
      "Sentence, : sentenc\n",
      "stems, : stem\n",
      "give, : give\n",
      "students, : student\n",
      "the, : the\n",
      "inertia, : inertia\n",
      "to, : to\n",
      "get, : get\n",
      "their, : their\n",
      "thoughts, : thought\n",
      "going, : go\n",
      "., : .\n",
      "Then, : then\n",
      "their, : their\n",
      "sentences, : sentenc\n",
      "bloom, : bloom\n",
      "., : .\n"
     ]
    }
   ],
   "source": [
    "from nltk import PorterStemmer\n",
    "from nltk import word_tokenize\n",
    "\n",
    "p=PorterStemmer()\n",
    "\n",
    "# stem is basically one who convert a perticular word into its root form and make our life simple \n",
    "# as we see liked, likely, liking are words derived from single word like \n",
    "# so we will find such words and print the root word for them\n",
    "\n",
    "a=\"Sentence Stems or Sentence Frames\\\n",
    "    Picture WHAT IS THE DIFFERENCE AND WHY SHOULD WE CARE?  Well, first and foremost,\\\n",
    "    we should care if we want our students to speak like scholars. If we want our \\\n",
    "    students to be marketable after they graduate. If we want them TO graduate! \\\n",
    "    Then we should care! Sentence stems and frames are scaffolds as students learn \\\n",
    "    language and content.  Sometimes educators use the terms sentence stems, sentence starters and sentence\\\n",
    "    frames interchangeably.You may wonder...are they the same thing? The answer is no, they are are not the \\\n",
    "    same. They have their own form and function. Sentence Frames Sentence frames essentially frame a sentence \\\n",
    "    and students add in some verbiage. Think of a picture frame where you add in a picture.  Sentence frames \\\n",
    "    look very much like traditional fill in the blank sentences. Here are some examples of sentence frames:\\\n",
    "    Sentence frames are scaffolds that may fit the needs of English learners at beginning levels of English \\\n",
    "    proficiency.  Some students may also benefit from visuals and word banks. However, sentence frames can be\\\n",
    "    used with English learners at higher levels of English proficiency to teach specific language structures \\\n",
    "    or to teach mortar words/tier II words.A sentence stem is the beginning of a sentence. Think of the stem of \\\n",
    "    a plant.  It's not the whole plant, just the beginning of it. It helps students get their sentence started.\\\n",
    "    Sometimes we use the term sentence starter interchangeably. Sentence stems give students the inertia to\\\n",
    "    get their thoughts going. Then their sentences bloom.\" \n",
    "\n",
    "tokens=word_tokenize(a)\n",
    "\n",
    "for i in range(len(tokens)):\n",
    "    print(tokens[i]+ \", : \"+ p.stem(tokens[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentence, : sent\n",
      "Stems, : stem\n",
      "or, : or\n",
      "Sentence, : sent\n",
      "Frames, : fram\n",
      "Picture, : pict\n",
      "WHAT, : what\n",
      "IS, : is\n",
      "THE, : the\n",
      "DIFFERENCE, : diff\n",
      "AND, : and\n",
      "WHY, : why\n",
      "SHOULD, : should\n",
      "WE, : we\n",
      "CARE, : car\n",
      "?, : ?\n",
      "Well, : wel\n",
      ",, : ,\n",
      "first, : first\n",
      "and, : and\n",
      "foremost, : foremost\n",
      ",, : ,\n",
      "we, : we\n",
      "should, : should\n",
      "care, : car\n",
      "if, : if\n",
      "we, : we\n",
      "want, : want\n",
      "our, : our\n",
      "students, : stud\n",
      "to, : to\n",
      "speak, : speak\n",
      "like, : lik\n",
      "scholars, : scholars\n",
      "., : .\n",
      "If, : if\n",
      "we, : we\n",
      "want, : want\n",
      "our, : our\n",
      "students, : stud\n",
      "to, : to\n",
      "be, : be\n",
      "marketable, : market\n",
      "after, : aft\n",
      "they, : they\n",
      "graduate, : gradu\n",
      "., : .\n",
      "If, : if\n",
      "we, : we\n",
      "want, : want\n",
      "them, : them\n",
      "TO, : to\n",
      "graduate, : gradu\n",
      "!, : !\n",
      "Then, : then\n",
      "we, : we\n",
      "should, : should\n",
      "care, : car\n",
      "!, : !\n",
      "Sentence, : sent\n",
      "stems, : stem\n",
      "and, : and\n",
      "frames, : fram\n",
      "are, : ar\n",
      "scaffolds, : scaffold\n",
      "as, : as\n",
      "students, : stud\n",
      "learn, : learn\n",
      "language, : langu\n",
      "and, : and\n",
      "content, : cont\n",
      "., : .\n",
      "Sometimes, : sometim\n",
      "educators, : educ\n",
      "use, : us\n",
      "the, : the\n",
      "terms, : term\n",
      "sentence, : sent\n",
      "stems, : stem\n",
      ",, : ,\n",
      "sentence, : sent\n",
      "starters, : start\n",
      "and, : and\n",
      "sentence, : sent\n",
      "frames, : fram\n",
      "interchangeably.You, : interchangeably.you\n",
      "may, : may\n",
      "wonder, : wond\n",
      "..., : ...\n",
      "are, : ar\n",
      "they, : they\n",
      "the, : the\n",
      "same, : sam\n",
      "thing, : thing\n",
      "?, : ?\n",
      "The, : the\n",
      "answer, : answ\n",
      "is, : is\n",
      "no, : no\n",
      ",, : ,\n",
      "they, : they\n",
      "are, : ar\n",
      "are, : ar\n",
      "not, : not\n",
      "the, : the\n",
      "same, : sam\n",
      "., : .\n",
      "They, : they\n",
      "have, : hav\n",
      "their, : their\n",
      "own, : own\n",
      "form, : form\n",
      "and, : and\n",
      "function, : funct\n",
      "., : .\n",
      "Sentence, : sent\n",
      "Frames, : fram\n",
      "Sentence, : sent\n",
      "frames, : fram\n",
      "essentially, : ess\n",
      "frame, : fram\n",
      "a, : a\n",
      "sentence, : sent\n",
      "and, : and\n",
      "students, : stud\n",
      "add, : ad\n",
      "in, : in\n",
      "some, : som\n",
      "verbiage, : verby\n",
      "., : .\n",
      "Think, : think\n",
      "of, : of\n",
      "a, : a\n",
      "picture, : pict\n",
      "frame, : fram\n",
      "where, : wher\n",
      "you, : you\n",
      "add, : ad\n",
      "in, : in\n",
      "a, : a\n",
      "picture, : pict\n",
      "., : .\n",
      "Sentence, : sent\n",
      "frames, : fram\n",
      "look, : look\n",
      "very, : very\n",
      "much, : much\n",
      "like, : lik\n",
      "traditional, : tradit\n",
      "fill, : fil\n",
      "in, : in\n",
      "the, : the\n",
      "blank, : blank\n",
      "sentences, : sent\n",
      "., : .\n",
      "Here, : her\n",
      "are, : ar\n",
      "some, : som\n",
      "examples, : exampl\n",
      "of, : of\n",
      "sentence, : sent\n",
      "frames, : fram\n",
      ":, : :\n",
      "Sentence, : sent\n",
      "frames, : fram\n",
      "are, : ar\n",
      "scaffolds, : scaffold\n",
      "that, : that\n",
      "may, : may\n",
      "fit, : fit\n",
      "the, : the\n",
      "needs, : nee\n",
      "of, : of\n",
      "English, : engl\n",
      "learners, : learn\n",
      "at, : at\n",
      "beginning, : begin\n",
      "levels, : level\n",
      "of, : of\n",
      "English, : engl\n",
      "proficiency, : proficy\n",
      "., : .\n",
      "Some, : som\n",
      "students, : stud\n",
      "may, : may\n",
      "also, : also\n",
      "benefit, : benefit\n",
      "from, : from\n",
      "visuals, : vis\n",
      "and, : and\n",
      "word, : word\n",
      "banks, : bank\n",
      "., : .\n",
      "However, : howev\n",
      ",, : ,\n",
      "sentence, : sent\n",
      "frames, : fram\n",
      "can, : can\n",
      "be, : be\n",
      "used, : us\n",
      "with, : with\n",
      "English, : engl\n",
      "learners, : learn\n",
      "at, : at\n",
      "higher, : high\n",
      "levels, : level\n",
      "of, : of\n",
      "English, : engl\n",
      "proficiency, : proficy\n",
      "to, : to\n",
      "teach, : teach\n",
      "specific, : spec\n",
      "language, : langu\n",
      "structures, : structures\n",
      "or, : or\n",
      "to, : to\n",
      "teach, : teach\n",
      "mortar, : mort\n",
      "words/tier, : words/tier\n",
      "II, : ii\n",
      "words.A, : words.a\n",
      "sentence, : sent\n",
      "stem, : stem\n",
      "is, : is\n",
      "the, : the\n",
      "beginning, : begin\n",
      "of, : of\n",
      "a, : a\n",
      "sentence, : sent\n",
      "., : .\n",
      "Think, : think\n",
      "of, : of\n",
      "the, : the\n",
      "stem, : stem\n",
      "of, : of\n",
      "a, : a\n",
      "plant, : plant\n",
      "., : .\n",
      "It, : it\n",
      "'s, : 's\n",
      "not, : not\n",
      "the, : the\n",
      "whole, : whol\n",
      "plant, : plant\n",
      ",, : ,\n",
      "just, : just\n",
      "the, : the\n",
      "beginning, : begin\n",
      "of, : of\n",
      "it, : it\n",
      "., : .\n",
      "It, : it\n",
      "helps, : help\n",
      "students, : stud\n",
      "get, : get\n",
      "their, : their\n",
      "sentence, : sent\n",
      "started, : start\n",
      "., : .\n",
      "Sometimes, : sometim\n",
      "we, : we\n",
      "use, : us\n",
      "the, : the\n",
      "term, : term\n",
      "sentence, : sent\n",
      "starter, : start\n",
      "interchangeably, : interchang\n",
      "., : .\n",
      "Sentence, : sent\n",
      "stems, : stem\n",
      "give, : giv\n",
      "students, : stud\n",
      "the, : the\n",
      "inertia, : inert\n",
      "to, : to\n",
      "get, : get\n",
      "their, : their\n",
      "thoughts, : thought\n",
      "going, : going\n",
      "., : .\n",
      "Then, : then\n",
      "their, : their\n",
      "sentences, : sent\n",
      "bloom, : bloom\n",
      "., : .\n"
     ]
    }
   ],
   "source": [
    "from nltk import LancasterStemmer\n",
    "from nltk import word_tokenize\n",
    "\n",
    "p=LancasterStemmer()\n",
    "\n",
    "# stem is basically one who convert a perticular word into its root form and make our life simple \n",
    "# as we see liked, likely, liking are words derived from single word like \n",
    "# so we will find such words and print the root word for them\n",
    "\n",
    "a=\"Sentence Stems or Sentence Frames\\\n",
    "    Picture WHAT IS THE DIFFERENCE AND WHY SHOULD WE CARE?  Well, first and foremost,\\\n",
    "    we should care if we want our students to speak like scholars. If we want our \\\n",
    "    students to be marketable after they graduate. If we want them TO graduate! \\\n",
    "    Then we should care! Sentence stems and frames are scaffolds as students learn \\\n",
    "    language and content.  Sometimes educators use the terms sentence stems, sentence starters and sentence\\\n",
    "    frames interchangeably.You may wonder...are they the same thing? The answer is no, they are are not the \\\n",
    "    same. They have their own form and function. Sentence Frames Sentence frames essentially frame a sentence \\\n",
    "    and students add in some verbiage. Think of a picture frame where you add in a picture.  Sentence frames \\\n",
    "    look very much like traditional fill in the blank sentences. Here are some examples of sentence frames:\\\n",
    "    Sentence frames are scaffolds that may fit the needs of English learners at beginning levels of English \\\n",
    "    proficiency.  Some students may also benefit from visuals and word banks. However, sentence frames can be\\\n",
    "    used with English learners at higher levels of English proficiency to teach specific language structures \\\n",
    "    or to teach mortar words/tier II words.A sentence stem is the beginning of a sentence. Think of the stem of \\\n",
    "    a plant.  It's not the whole plant, just the beginning of it. It helps students get their sentence started.\\\n",
    "    Sometimes we use the term sentence starter interchangeably. Sentence stems give students the inertia to\\\n",
    "    get their thoughts going. Then their sentences bloom.\" \n",
    "\n",
    "tokens=word_tokenize(a)\n",
    "\n",
    "for i in range(len(tokens)):\n",
    "    print(tokens[i]+ \", : \"+ p.stem(tokens[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentence, : sent\n",
      "Stems, : stem\n",
      "or, : or\n",
      "Sentence, : sent\n",
      "Frames, : fram\n",
      "Picture, : pict\n",
      "WHAT, : what\n",
      "IS, : is\n",
      "THE, : the\n",
      "DIFFERENCE, : diff\n",
      "AND, : and\n",
      "WHY, : why\n",
      "SHOULD, : should\n",
      "WE, : we\n",
      "CARE, : car\n",
      "?, : ?\n",
      "Well, : wel\n",
      ",, : ,\n",
      "first, : first\n",
      "and, : and\n",
      "foremost, : foremost\n",
      ",, : ,\n",
      "we, : we\n",
      "should, : should\n",
      "care, : car\n",
      "if, : if\n",
      "we, : we\n",
      "want, : want\n",
      "our, : our\n",
      "students, : stud\n",
      "to, : to\n",
      "speak, : speak\n",
      "like, : lik\n",
      "scholars, : scholars\n",
      "., : .\n",
      "If, : if\n",
      "we, : we\n",
      "want, : want\n",
      "our, : our\n",
      "students, : stud\n",
      "to, : to\n",
      "be, : be\n",
      "marketable, : market\n",
      "after, : aft\n",
      "they, : they\n",
      "graduate, : gradu\n",
      "., : .\n",
      "If, : if\n",
      "we, : we\n",
      "want, : want\n",
      "them, : them\n",
      "TO, : to\n",
      "graduate, : gradu\n",
      "!, : !\n",
      "Then, : then\n",
      "we, : we\n",
      "should, : should\n",
      "care, : car\n",
      "!, : !\n",
      "Sentence, : sent\n",
      "stems, : stem\n",
      "and, : and\n",
      "frames, : fram\n",
      "are, : ar\n",
      "scaffolds, : scaffold\n",
      "as, : as\n",
      "students, : stud\n",
      "learn, : learn\n",
      "language, : langu\n",
      "and, : and\n",
      "content, : cont\n",
      "., : .\n",
      "Sometimes, : sometim\n",
      "educators, : educ\n",
      "use, : us\n",
      "the, : the\n",
      "terms, : term\n",
      "sentence, : sent\n",
      "stems, : stem\n",
      ",, : ,\n",
      "sentence, : sent\n",
      "starters, : start\n",
      "and, : and\n",
      "sentence, : sent\n",
      "frames, : fram\n",
      "interchangeably.You, : interchangeably.you\n",
      "may, : may\n",
      "wonder, : wond\n",
      "..., : ...\n",
      "are, : ar\n",
      "they, : they\n",
      "the, : the\n",
      "same, : sam\n",
      "thing, : thing\n",
      "?, : ?\n",
      "The, : the\n",
      "answer, : answ\n",
      "is, : is\n",
      "no, : no\n",
      ",, : ,\n",
      "they, : they\n",
      "are, : ar\n",
      "are, : ar\n",
      "not, : not\n",
      "the, : the\n",
      "same, : sam\n",
      "., : .\n",
      "They, : they\n",
      "have, : hav\n",
      "their, : their\n",
      "own, : own\n",
      "form, : form\n",
      "and, : and\n",
      "function, : funct\n",
      "., : .\n",
      "Sentence, : sent\n",
      "Frames, : fram\n",
      "Sentence, : sent\n",
      "frames, : fram\n",
      "essentially, : ess\n",
      "frame, : fram\n",
      "a, : a\n",
      "sentence, : sent\n",
      "and, : and\n",
      "students, : stud\n",
      "add, : ad\n",
      "in, : in\n",
      "some, : som\n",
      "verbiage, : verby\n",
      "., : .\n",
      "Think, : think\n",
      "of, : of\n",
      "a, : a\n",
      "picture, : pict\n",
      "frame, : fram\n",
      "where, : wher\n",
      "you, : you\n",
      "add, : ad\n",
      "in, : in\n",
      "a, : a\n",
      "picture, : pict\n",
      "., : .\n",
      "Sentence, : sent\n",
      "frames, : fram\n",
      "look, : look\n",
      "very, : very\n",
      "much, : much\n",
      "like, : lik\n",
      "traditional, : tradit\n",
      "fill, : fil\n",
      "in, : in\n",
      "the, : the\n",
      "blank, : blank\n",
      "sentences, : sent\n",
      "., : .\n",
      "Here, : her\n",
      "are, : ar\n",
      "some, : som\n",
      "examples, : exampl\n",
      "of, : of\n",
      "sentence, : sent\n",
      "frames, : fram\n",
      ":, : :\n",
      "Sentence, : sent\n",
      "frames, : fram\n",
      "are, : ar\n",
      "scaffolds, : scaffold\n",
      "that, : that\n",
      "may, : may\n",
      "fit, : fit\n",
      "the, : the\n",
      "needs, : nee\n",
      "of, : of\n",
      "English, : engl\n",
      "learners, : learn\n",
      "at, : at\n",
      "beginning, : begin\n",
      "levels, : level\n",
      "of, : of\n",
      "English, : engl\n",
      "proficiency, : proficy\n",
      "., : .\n",
      "Some, : som\n",
      "students, : stud\n",
      "may, : may\n",
      "also, : also\n",
      "benefit, : benefit\n",
      "from, : from\n",
      "visuals, : vis\n",
      "and, : and\n",
      "word, : word\n",
      "banks, : bank\n",
      "., : .\n",
      "However, : howev\n",
      ",, : ,\n",
      "sentence, : sent\n",
      "frames, : fram\n",
      "can, : can\n",
      "be, : be\n",
      "used, : us\n",
      "with, : with\n",
      "English, : engl\n",
      "learners, : learn\n",
      "at, : at\n",
      "higher, : high\n",
      "levels, : level\n",
      "of, : of\n",
      "English, : engl\n",
      "proficiency, : proficy\n",
      "to, : to\n",
      "teach, : teach\n",
      "specific, : spec\n",
      "language, : langu\n",
      "structures, : structures\n",
      "or, : or\n",
      "to, : to\n",
      "teach, : teach\n",
      "mortar, : mort\n",
      "words/tier, : words/tier\n",
      "II, : ii\n",
      "words.A, : words.a\n",
      "sentence, : sent\n",
      "stem, : stem\n",
      "is, : is\n",
      "the, : the\n",
      "beginning, : begin\n",
      "of, : of\n",
      "a, : a\n",
      "sentence, : sent\n",
      "., : .\n",
      "Think, : think\n",
      "of, : of\n",
      "the, : the\n",
      "stem, : stem\n",
      "of, : of\n",
      "a, : a\n",
      "plant, : plant\n",
      "., : .\n",
      "It, : it\n",
      "'s, : 's\n",
      "not, : not\n",
      "the, : the\n",
      "whole, : whol\n",
      "plant, : plant\n",
      ",, : ,\n",
      "just, : just\n",
      "the, : the\n",
      "beginning, : begin\n",
      "of, : of\n",
      "it, : it\n",
      "., : .\n",
      "It, : it\n",
      "helps, : help\n",
      "students, : stud\n",
      "get, : get\n",
      "their, : their\n",
      "sentence, : sent\n",
      "started, : start\n",
      "., : .\n",
      "Sometimes, : sometim\n",
      "we, : we\n",
      "use, : us\n",
      "the, : the\n",
      "term, : term\n",
      "sentence, : sent\n",
      "starter, : start\n",
      "interchangeably, : interchang\n",
      "., : .\n",
      "Sentence, : sent\n",
      "stems, : stem\n",
      "give, : giv\n",
      "students, : stud\n",
      "the, : the\n",
      "inertia, : inert\n",
      "to, : to\n",
      "get, : get\n",
      "their, : their\n",
      "thoughts, : thought\n",
      "going, : going\n",
      "., : .\n",
      "Then, : then\n",
      "their, : their\n",
      "sentences, : sent\n",
      "bloom, : bloom\n",
      "., : .\n"
     ]
    }
   ],
   "source": [
    "from nltk import PorterStemmer\n",
    "from nltk import word_tokenize\n",
    "\n",
    "p=LancasterStemmer()\n",
    "\n",
    "# stem is basically one who convert a perticular word into its root form and make our life simple \n",
    "# as we see liked, likely, liking are words derived from single word like \n",
    "# so we will find such words and print the root word for them\n",
    "\n",
    "a=\"Sentence Stems or Sentence Frames\\\n",
    "    Picture WHAT IS THE DIFFERENCE AND WHY SHOULD WE CARE?  Well, first and foremost,\\\n",
    "    we should care if we want our students to speak like scholars. If we want our \\\n",
    "    students to be marketable after they graduate. If we want them TO graduate! \\\n",
    "    Then we should care! Sentence stems and frames are scaffolds as students learn \\\n",
    "    language and content.  Sometimes educators use the terms sentence stems, sentence starters and sentence\\\n",
    "    frames interchangeably.You may wonder...are they the same thing? The answer is no, they are are not the \\\n",
    "    same. They have their own form and function. Sentence Frames Sentence frames essentially frame a sentence \\\n",
    "    and students add in some verbiage. Think of a picture frame where you add in a picture.  Sentence frames \\\n",
    "    look very much like traditional fill in the blank sentences. Here are some examples of sentence frames:\\\n",
    "    Sentence frames are scaffolds that may fit the needs of English learners at beginning levels of English \\\n",
    "    proficiency.  Some students may also benefit from visuals and word banks. However, sentence frames can be\\\n",
    "    used with English learners at higher levels of English proficiency to teach specific language structures \\\n",
    "    or to teach mortar words/tier II words.A sentence stem is the beginning of a sentence. Think of the stem of \\\n",
    "    a plant.  It's not the whole plant, just the beginning of it. It helps students get their sentence started.\\\n",
    "    Sometimes we use the term sentence starter interchangeably. Sentence stems give students the inertia to\\\n",
    "    get their thoughts going. Then their sentences bloom.\" \n",
    "\n",
    "tokens=word_tokenize(a)\n",
    "\n",
    "for i in range(len(tokens)):\n",
    "    print(tokens[i]+ \", : \"+ p.stem(tokens[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentence, : sent\n",
      "Stems, : stem\n",
      "or, : or\n",
      "Sentence, : sent\n",
      "Frames, : fram\n",
      "Picture, : pict\n",
      "WHAT, : what\n",
      "IS, : is\n",
      "THE, : the\n",
      "DIFFERENCE, : diff\n",
      "AND, : and\n",
      "WHY, : why\n",
      "SHOULD, : should\n",
      "WE, : we\n",
      "CARE, : car\n",
      "?, : ?\n",
      "Well, : wel\n",
      ",, : ,\n",
      "first, : first\n",
      "and, : and\n",
      "foremost, : foremost\n",
      ",, : ,\n",
      "we, : we\n",
      "should, : should\n",
      "care, : car\n",
      "if, : if\n",
      "we, : we\n",
      "want, : want\n",
      "our, : our\n",
      "students, : stud\n",
      "to, : to\n",
      "speak, : speak\n",
      "like, : lik\n",
      "scholars, : scholars\n",
      "., : .\n",
      "If, : if\n",
      "we, : we\n",
      "want, : want\n",
      "our, : our\n",
      "students, : stud\n",
      "to, : to\n",
      "be, : be\n",
      "marketable, : market\n",
      "after, : aft\n",
      "they, : they\n",
      "graduate, : gradu\n",
      "., : .\n",
      "If, : if\n",
      "we, : we\n",
      "want, : want\n",
      "them, : them\n",
      "TO, : to\n",
      "graduate, : gradu\n",
      "!, : !\n",
      "Then, : then\n",
      "we, : we\n",
      "should, : should\n",
      "care, : car\n",
      "!, : !\n",
      "Sentence, : sent\n",
      "stems, : stem\n",
      "and, : and\n",
      "frames, : fram\n",
      "are, : ar\n",
      "scaffolds, : scaffold\n",
      "as, : as\n",
      "students, : stud\n",
      "learn, : learn\n",
      "language, : langu\n",
      "and, : and\n",
      "content, : cont\n",
      "., : .\n",
      "Sometimes, : sometim\n",
      "educators, : educ\n",
      "use, : us\n",
      "the, : the\n",
      "terms, : term\n",
      "sentence, : sent\n",
      "stems, : stem\n",
      ",, : ,\n",
      "sentence, : sent\n",
      "starters, : start\n",
      "and, : and\n",
      "sentence, : sent\n",
      "frames, : fram\n",
      "interchangeably.You, : interchangeably.you\n",
      "may, : may\n",
      "wonder, : wond\n",
      "..., : ...\n",
      "are, : ar\n",
      "they, : they\n",
      "the, : the\n",
      "same, : sam\n",
      "thing, : thing\n",
      "?, : ?\n",
      "The, : the\n",
      "answer, : answ\n",
      "is, : is\n",
      "no, : no\n",
      ",, : ,\n",
      "they, : they\n",
      "are, : ar\n",
      "are, : ar\n",
      "not, : not\n",
      "the, : the\n",
      "same, : sam\n",
      "., : .\n",
      "They, : they\n",
      "have, : hav\n",
      "their, : their\n",
      "own, : own\n",
      "form, : form\n",
      "and, : and\n",
      "function, : funct\n",
      "., : .\n",
      "Sentence, : sent\n",
      "Frames, : fram\n",
      "Sentence, : sent\n",
      "frames, : fram\n",
      "essentially, : ess\n",
      "frame, : fram\n",
      "a, : a\n",
      "sentence, : sent\n",
      "and, : and\n",
      "students, : stud\n",
      "add, : ad\n",
      "in, : in\n",
      "some, : som\n",
      "verbiage, : verby\n",
      "., : .\n",
      "Think, : think\n",
      "of, : of\n",
      "a, : a\n",
      "picture, : pict\n",
      "frame, : fram\n",
      "where, : wher\n",
      "you, : you\n",
      "add, : ad\n",
      "in, : in\n",
      "a, : a\n",
      "picture, : pict\n",
      "., : .\n",
      "Sentence, : sent\n",
      "frames, : fram\n",
      "look, : look\n",
      "very, : very\n",
      "much, : much\n",
      "like, : lik\n",
      "traditional, : tradit\n",
      "fill, : fil\n",
      "in, : in\n",
      "the, : the\n",
      "blank, : blank\n",
      "sentences, : sent\n",
      "., : .\n",
      "Here, : her\n",
      "are, : ar\n",
      "some, : som\n",
      "examples, : exampl\n",
      "of, : of\n",
      "sentence, : sent\n",
      "frames, : fram\n",
      ":, : :\n",
      "Sentence, : sent\n",
      "frames, : fram\n",
      "are, : ar\n",
      "scaffolds, : scaffold\n",
      "that, : that\n",
      "may, : may\n",
      "fit, : fit\n",
      "the, : the\n",
      "needs, : nee\n",
      "of, : of\n",
      "English, : engl\n",
      "learners, : learn\n",
      "at, : at\n",
      "beginning, : begin\n",
      "levels, : level\n",
      "of, : of\n",
      "English, : engl\n",
      "proficiency, : proficy\n",
      "., : .\n",
      "Some, : som\n",
      "students, : stud\n",
      "may, : may\n",
      "also, : also\n",
      "benefit, : benefit\n",
      "from, : from\n",
      "visuals, : vis\n",
      "and, : and\n",
      "word, : word\n",
      "banks, : bank\n",
      "., : .\n",
      "However, : howev\n",
      ",, : ,\n",
      "sentence, : sent\n",
      "frames, : fram\n",
      "can, : can\n",
      "be, : be\n",
      "used, : us\n",
      "with, : with\n",
      "English, : engl\n",
      "learners, : learn\n",
      "at, : at\n",
      "higher, : high\n",
      "levels, : level\n",
      "of, : of\n",
      "English, : engl\n",
      "proficiency, : proficy\n",
      "to, : to\n",
      "teach, : teach\n",
      "specific, : spec\n",
      "language, : langu\n",
      "structures, : structures\n",
      "or, : or\n",
      "to, : to\n",
      "teach, : teach\n",
      "mortar, : mort\n",
      "words/tier, : words/tier\n",
      "II, : ii\n",
      "words.A, : words.a\n",
      "sentence, : sent\n",
      "stem, : stem\n",
      "is, : is\n",
      "the, : the\n",
      "beginning, : begin\n",
      "of, : of\n",
      "a, : a\n",
      "sentence, : sent\n",
      "., : .\n",
      "Think, : think\n",
      "of, : of\n",
      "the, : the\n",
      "stem, : stem\n",
      "of, : of\n",
      "a, : a\n",
      "plant, : plant\n",
      "., : .\n",
      "It, : it\n",
      "'s, : 's\n",
      "not, : not\n",
      "the, : the\n",
      "whole, : whol\n",
      "plant, : plant\n",
      ",, : ,\n",
      "just, : just\n",
      "the, : the\n",
      "beginning, : begin\n",
      "of, : of\n",
      "it, : it\n",
      "., : .\n",
      "It, : it\n",
      "helps, : help\n",
      "students, : stud\n",
      "get, : get\n",
      "their, : their\n",
      "sentence, : sent\n",
      "started, : start\n",
      "., : .\n",
      "Sometimes, : sometim\n",
      "we, : we\n",
      "use, : us\n",
      "the, : the\n",
      "term, : term\n",
      "sentence, : sent\n",
      "starter, : start\n",
      "interchangeably, : interchang\n",
      "., : .\n",
      "Sentence, : sent\n",
      "stems, : stem\n",
      "give, : giv\n",
      "students, : stud\n",
      "the, : the\n",
      "inertia, : inert\n",
      "to, : to\n",
      "get, : get\n",
      "their, : their\n",
      "thoughts, : thought\n",
      "going, : going\n",
      "., : .\n",
      "Then, : then\n",
      "their, : their\n",
      "sentences, : sent\n",
      "bloom, : bloom\n",
      "., : .\n"
     ]
    }
   ],
   "source": [
    "from nltk import SnowballStemmer\n",
    "from nltk import word_tokenize\n",
    "\n",
    "p=LancasterStemmer()\n",
    "\n",
    "# stem is basically one who convert a perticular word into its root form and make our life simple \n",
    "# as we see liked, likely, liking are words derived from single word like \n",
    "# so we will find such words and print the root word for them\n",
    "\n",
    "a=\"Sentence Stems or Sentence Frames\\\n",
    "    Picture WHAT IS THE DIFFERENCE AND WHY SHOULD WE CARE?  Well, first and foremost,\\\n",
    "    we should care if we want our students to speak like scholars. If we want our \\\n",
    "    students to be marketable after they graduate. If we want them TO graduate! \\\n",
    "    Then we should care! Sentence stems and frames are scaffolds as students learn \\\n",
    "    language and content.  Sometimes educators use the terms sentence stems, sentence starters and sentence\\\n",
    "    frames interchangeably.You may wonder...are they the same thing? The answer is no, they are are not the \\\n",
    "    same. They have their own form and function. Sentence Frames Sentence frames essentially frame a sentence \\\n",
    "    and students add in some verbiage. Think of a picture frame where you add in a picture.  Sentence frames \\\n",
    "    look very much like traditional fill in the blank sentences. Here are some examples of sentence frames:\\\n",
    "    Sentence frames are scaffolds that may fit the needs of English learners at beginning levels of English \\\n",
    "    proficiency.  Some students may also benefit from visuals and word banks. However, sentence frames can be\\\n",
    "    used with English learners at higher levels of English proficiency to teach specific language structures \\\n",
    "    or to teach mortar words/tier II words.A sentence stem is the beginning of a sentence. Think of the stem of \\\n",
    "    a plant.  It's not the whole plant, just the beginning of it. It helps students get their sentence started.\\\n",
    "    Sometimes we use the term sentence starter interchangeably. Sentence stems give students the inertia to\\\n",
    "    get their thoughts going. Then their sentences bloom.\" \n",
    "\n",
    "tokens=word_tokenize(a)\n",
    "\n",
    "for i in range(len(tokens)):\n",
    "    print(tokens[i]+ \", : \"+ p.stem(tokens[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to /home/ghansham/nltk_data...\n",
      "[nltk_data] Downloading package omw-1.4 to /home/ghansham/nltk_data...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Lammetizer\n",
    "nltk.download('wordnet')\n",
    "nltk.download('omw-1.4')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentence, : Sentence\n",
      "Stems, : Stems\n",
      "or, : or\n",
      "Sentence, : Sentence\n",
      "Frames, : Frames\n"
     ]
    }
   ],
   "source": [
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "p=WordNetLemmatizer()\n",
    "\n",
    "# stem is basically one who convert a perticular word into its root form and make our life simple \n",
    "# as we see liked, likely, liking are words derived from single word like \n",
    "# so we will find such words and print the root word for them\n",
    "\n",
    "a=\"Sentence Stems or Sentence Frames\"\n",
    "tokens=word_tokenize(a)\n",
    "\n",
    "for i in range(len(tokens)):\n",
    "    print(tokens[i]+ \", : \"+ p.lemmatize(tokens[i]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
