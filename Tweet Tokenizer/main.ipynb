{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# installing / checking that is nltk is there in the system if not this will install it \n",
    "# pip install nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# after downloading the nltk we will import it in our system \n",
    "import nltk as nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output of Read function is \n",
      "24906\n",
      "<class 'str'>\n"
     ]
    }
   ],
   "source": [
    "# getting data from the file to as a string and we will process it further \n",
    "file1 = open(\"Input Dataset.txt\",\"r+\") \n",
    "  \n",
    "print(\"Output of Read function is \")\n",
    "c=file1.read()\n",
    "# print(c)\n",
    "# printing the len of file and the type of after reading through the file \n",
    "print(len(c))\n",
    "print(type(c))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /home/ghansham/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# it is showing error so we download the punkt to avoid this error \n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# so for your info tokenizer are present inside nltk.tokenize from nltk.tokenize you can get word_tokenize and other tokenizers \n",
    "# on basis of spaces and on basis of spaces tokens are getting created\n",
    "# so as i need the words and the punchuations im using word tokenization\n",
    "from nltk import word_tokenize\n",
    "tokens=word_tokenize(c) # tokenize with word tokenize \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5083\n"
     ]
    }
   ],
   "source": [
    "print(len(tokens))\n",
    "# print(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now importing the tweetTokenizer and then we will process it further \n",
    "from nltk.tokenize import TweetTokenizer\n",
    "tweetTokens=TweetTokenizer(tokens) # this will give a tokenizer object as the result \n",
    "# now convert the tokens into the list or array \n",
    "tweetTokens=tweetTokens.tokenize(c)\n",
    "pass\n",
    "# print(tweetTokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now we will search for conflicts words and create a set and then we will fetch them and will find the solution "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"It's\", \"It's\", \"it's\", \"we're\", \"we've\", \"i'd've\", \"ain't\", \"shouldn't\", \"i'm\", \"can't\", \"i'm\", \"Can't\", \"Shouldn't\", \"How's\", \"i'd've\", \"i'll\", \"he'd\", \"I'm\", \"don't\", \"didn't\", \"hadn't\", \"it's\", \"can't\", \"It's\", \"Today's\", \"Suprit's\", \"won't\", \"I'd\", \"Today's\", \"I've\", \"He's\", \"it's\", \"It's\", \"Won't\", \"understanding's\", \"you'll\", \"wouldn't\", \"Can't\", \"I'd\", \"I'VE\", \"anyone's\", \"Can't\", \"That's\", \"I'll\", \"I'm\", \"don't\", \"I'm\", \"aren't\", \"can't\", \"I'm\", \"I'm\", \"I'm\", \"it'll\", \"can't\", \"addit'n\", \"We'll\", \"Didn't\", \"I'm\", \"I'll\", \"mobile's\", \"Don't\", \"couldn't\", \"fanboy's\", \"didn't\", \"it's\", \"aren't\", \"I'm\", \"I've\", \"It's\", \"It's\", \"couldn't\", \"won't\", \"mobile's\", \"l'assistenza\", \"doesn't\", \"YOU'RE\", \"Wasn't\", \"that's\", \"It's\", \"It's\", \"helicopter's\", \"won't\", \"can't\", \"It's\", \"didn't\", \"Who's\", \"Can't\", \"didn't\", \"Who's\", \"Can't\", \"don't\"]\n",
      "91\n"
     ]
    }
   ],
   "source": [
    "# code which will give you all conflict words having apostrophy inside them \n",
    "fd=[]\n",
    "for i in tweetTokens:\n",
    "    if \"'\" in i and len(i)>1:\n",
    "        fd.append(i)\n",
    "print(fd)\n",
    "print(len(fd))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['It', 'is', 'It', 'is', 'it', 'is', \"we're\", 'w', 'have', 'i', 'had', 'ai', 'not', 'should', 'not', 'i', 'am', 'can', 'not', 'i', 'am', 'can', 'not', 'Should', 'not', 'How', 'is', 'i', 'had', 'i', 'will', 'he', 'had', 'I', 'am', 'do', 'not', 'did', 'not', 'had', 'not', 'it', 'is', 'can', 'not', 'It', 'is', 'Today', 'is', 'Suprit', 'is', 'would', 'not', 'I', 'had', 'Today', 'is', '', 'have', 'He', 'is', 'it', 'is', 'It', 'is', 'Wo', 'not', 'understanding', 'is', 'you', 'will', 'would', 'not', 'can', 'not', 'I', 'had', '', 'have', 'anyone', 'is', 'can', 'not', 'That', 'is', 'I', 'will', 'I', 'am', 'do', 'not', 'I', 'am', 'are', 'not', 'can', 'not', 'I', 'am', 'I', 'am', 'I', 'am', 'it', 'will', 'can', 'not', \"addit'n\", 'We', 'will', 'Did', 'not', 'I', 'am', 'I', 'will', 'mobile', 'is', 'Do', 'not', 'could', 'not', 'fanboy', 'is', 'did', 'not', 'it', 'is', 'are', 'not', 'I', 'am', '', 'have', 'It', 'is', 'It', 'is', 'could', 'not', 'would', 'not', 'mobile', 'is', \"l'assistenza\", 'does', 'not', \"YOU'RE\", 'Was', 'not', 'that', 'is', 'It', 'is', 'It', 'is', 'helicopter', 'is', 'would', 'not', 'can', 'not', 'It', 'is', 'did', 'not', 'Who', 'is', 'can', 'not', 'did', 'not', 'Who', 'is', 'can', 'not', 'do', 'not']\n",
      "178\n"
     ]
    }
   ],
   "source": [
    "def parsing(fd):\n",
    "    l=[]\n",
    "    for i in range(len(fd)):\n",
    "        f=fd[i].index(\"'\")\n",
    "        if(fd[i][f+1]==\"s\" or fd[i][f+1]==\"S\"):\n",
    "            l.append(fd[i][:f])\n",
    "            l.append(\"is\")\n",
    "        elif(fd[i][f+1]==\"t\" or fd[i][f+1]==\"T\"):\n",
    "            if(fd[i][:f]==\"can\" or fd[i][:f]==\"Can\" ):\n",
    "                l.append(\"can\")\n",
    "                l.append(\"not\")\n",
    "            elif(fd[i][:f]==\"won\" or fd[i][:f]==\"Wont\" ):\n",
    "                l.append(\"would\")\n",
    "                l.append(\"not\")\n",
    "            else:\n",
    "                l.append(fd[i][:f-1])\n",
    "                l.append(\"not\")\n",
    "        elif(fd[i][f+1]==\"v\" or fd[i][f+1]==\"V\"):\n",
    "            l.append(fd[i][:f-1])\n",
    "            l.append(\"have\")\n",
    "        elif(fd[i][f+1]==\"m\" or fd[i][f+1]==\"M\"):\n",
    "            l.append(fd[i][:f])\n",
    "            l.append(\"am\")\n",
    "        elif(fd[i][f+1]==\"l\" or fd[i][f+1]==\"L\"):\n",
    "            l.append(fd[i][:f])\n",
    "            l.append(\"will\")\n",
    "        elif(fd[i][f+1]==\"d\" or fd[i][f+1]==\"D\"):\n",
    "            l.append(fd[i][:f])\n",
    "            l.append(\"had\")\n",
    "        else:\n",
    "            l.append(fd[i])\n",
    "    return l\n",
    "\n",
    "gg=parsing(fd)\n",
    "print(gg)\n",
    "print(len(gg))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'A big thanks to @hhshkmohd for his gracious offer to support people of Kerala during this difficult time. His concern reflects the special ties between governments and people of India and UAE.\\n'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# code which gives us the input in the form of oneline at a time \n",
    "with open('Input Dataset.txt') as f:\n",
    "    lines = f.readlines()\n",
    "    \n",
    "lines[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('Ghansham', 'Salunkhe')"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def split_dash(sm):\n",
    "    a=sm.index(\"-\")\n",
    "    return sm[:a],sm[a+1:]\n",
    "split_dash(\"Ghansham-Salunkhe\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('US', 'Japan')\n",
      "('ggsd', 'ah')\n",
      "('US', 'basde')\n",
      "('US', 'based')\n",
      "('US', 'Japan')\n",
      "('15', '7-')\n",
      "('2013', '09-')\n",
      "('US', 'based')\n",
      "('start', 'up')\n",
      "('Indo', 'China')\n",
      "('08', '17-')\n",
      "('2018', '08-')\n",
      "('object', 'oriented')\n",
      "('Object', 'Oriented')\n",
      "('Over', 'view')\n",
      "('PULL', 'UP')\n",
      "('Snap', 'To')\n",
      "('in', 'store')\n",
      "('kick', 'butt')\n",
      "('pre', 'installed')\n",
      "('someday', '-via')\n",
      "('in', 'store')\n",
      "('time', 'traveling')\n",
      "('Work', 'Life')\n",
      "('command', 'line')\n",
      "('python', 'twitter')\n",
      "('python', 'twitter')\n",
      "('command', 'line')\n",
      "('python', 'twitter')\n",
      "('python', 'twitter')\n",
      "('straight', 'from-undergrad')\n",
      "('Public', 'Private')\n",
      "('python', 'twitter')\n"
     ]
    }
   ],
   "source": [
    "# this piece of code will give you word with having seperated by dash \n",
    "gd=[]\n",
    "for i in tweetTokens:\n",
    "    if \"-\" in i and len(i)>1 and i[0:4]!=\"http\" and i.isalpha()==False:\n",
    "        # gd.append(i)\n",
    "        print(split_dash(i))\n",
    "\n",
    "# gd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Ghansham', 'Rajaram', 'Salunkhe']"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Python3 program Split camel case\n",
    "# string to individual strings\n",
    "def camel_case_split(str1):\n",
    "    l=[]\n",
    "    n=0\n",
    "    if (str1.isalpha()):\n",
    "        s=str1[0]\n",
    "        n=n+1\n",
    "    else:\n",
    "        l.append(str1[0])\n",
    "        s=str1[1]\n",
    "        n=2\n",
    "\n",
    "    for i in range(n,len(str1)):\n",
    "        if(str1[i].isupper()):\n",
    "            l.append(s)\n",
    "            s=\"\"\n",
    "        s=s+str1[i]\n",
    "    l.append(s)\n",
    "    return l\n",
    "\n",
    "camel_case_split(\"GhanshamRajaramSalunkhe\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now we will check for words having camel case or not \n",
    "def checkForCamelCase(s):\n",
    "    return s != s.lower() and s != s.upper() and \"_\" not in s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to count capital letters inside the character\n",
    "def countUpperCharacters(s,n):\n",
    "    count=0\n",
    "    for i in range(n,len(s)):\n",
    "        if(s[i].isupper()):\n",
    "            count=count+1\n",
    "\n",
    "    return count\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['iGuess', '@IndiaCoastGuard', '#KeralaFloods', 'iGuess', 'ToWake', '@asawareeBhide', '#polkaDots', 'HipHappening', '#Burbank', '@DeBruyneKev', '@Madonna', '#RIPAtalBihariVaajpayee', '@suiDhaagafilm', 'iGuess', 'iPhone', '@Apple', '@Apple', 'iPhone', '#watchESPN', 'AppleTV', '@Apple', '@TraceyLiddle', '@Apple', '@Apple', 'iPhone', '#iPhone5C', '@Apple', 'iPhone', '@Apple', 'iPhoto', 'iMovie', 'iWork', 'iPad', '#iPhone5S', '#FingerprintsRecognitom', '#iPhone', '#Apple', '@Apple', '#Concepts', 'MacBooks', '@iBrooklynB', '@Apple', '@Windows', '@Apple', '@Apple', '#iOS7', '@Lafond66', '@Apple', 'iOS', '#iRadio', '@FastCoDesign', '@Apple', '#iPhone', '@iBrooklynB', '@Apple', '#Fell', '#Working', '@Apple', '@Apple', '@Samsung', 'LRWBlog', '#iPhone5s', '@Apple', 'MacBook', 'iPhone', 'iPhone', 'iPhone', '@Apple', '#itunesFestival', '@Apple', '@Microsoft', '@Windows', '@Apple', '@Apple', '#iPhone5S', '#iPhone', '#Apple', '#September20th', 'SLRs', '@FireandIce5935', '@Android', '@Apple', '@Apple', 'CoreMotion', 'iPhone', '@Apple', 'iPhones', 'iPhoto', 'iMovie', '@Apple', 'iPhones', 'iPhoto', 'iMovie', '@Sephora', '@Apple', 'industry.Incredible', '@Apple', '@ScaleBoxApp', '@Apple', '@iTunesMusic', '#Apple', '#iPhone', '#iTunes', '#iPhone5S', '@Apple', 'bPhone', '@Beyonce', '@Apple', 'iPhone', '@Apple', '#TouchID', '@Apple', '#courtsideassistappforiOS', 'iPhone', '@Apple', '#Iphone', '#Touch', '@Apple', '@Apple', '@TheMIXXRadio', '@TheMixxHangout', 'iPhone', '@TheDiMassa', '@Samsung', '@Apple', '@Apple', 'iPhone', '@ScaleBoxApp', '@Apple', '@iTunesMusic', '#Apple', '#iPhone', '#Piano', '#Music', '#OnlyClassical', '#Violin', '@Apple', '@Apple', 'iOS', '@Stratix', '@Apple', '#Tech', '@Apple', '@Samsung', '@Apple', '@BoeingAirplanes', '@Apple', '@iBrooklynB', '@Apple', '@Apple', '#Apple', 'iPhone', '#iOs', 'iPhone', '#Android', '#iPhone', '@Google', '@Apple', 'iPhones', 'iPhone', 'TouchID', '@Apple', 'iPhones', 'iPad', '@Apple', '#iPhone', '@BlakeGrahamPGA', '@BestBuy', '@Apple', 'iPhone', '#California', 'IPhone', '@Apple', '#iPhone', '#iOS7', '@Apple', '#Mobile', '#App', '@Apple', '@Apple', '@iMore', '@Apple', '#iPad', '#iWork', '@Apple', '@Apple', 'iOS', '@Apple', '#iPhone', 'iPhone', '@Nokia', '@Apple', '#WinPhan', '@Jon4Lakers', '@TechnoBuffalo', '@Apple', '@ETCanada', '@Clusocluso', '@Apple', '@Burberry', '#Digitallyperfect', '#Tech', '@Apple', '#iPhone5C', 'iOS', '@Apple', '@Apple', '#Innovation', '@JMLColley', '@Apple', '@TheEspinAlien', '@iBrooklynB', '@Apple', 'iPhone', '#Iphone5c', '@highlyHIGHtori', '@Apple', '#AppleFreak', '@Apple', '@Apple', 'iPhone', 'iPhone', 'iOS', '#iPhone', 'iPhone', '@7evenStarz', '@Apple', '#JonyIve', '#iPhone5c', '@Apple', '@OITHelpDesk', '@Apple', '#iPhone5C', '#Pink', '#ApplePicking', '@Sprint', '@Samsung', '@Apple', '@MissPhilly2013', '@Apple', '#iOS7', '@Apple', 'iPhones', '@7evenStarz', '@Apple', '@Apple', 'iPhone', '#India', '#eBayCheck', '@eBayIndia', '#eBayCheck', '@Apple', 'iPhone', 'iPad', '@Om', '@Apple', 'iPhones', '#iBeacons', '#iOS', '#iPhone', 'iPhones', '@Apple', '@iBrooklynB', '@Apple', '@EllieDash', '@DaveLeeBBC', '@Lexxxzis', '@SuperCoolCube', '@MolecularLove', '@RyanLochte', 'UANews', '#BearDown', '@NatalieCoughlin', '#CDoM', '@RickyBerens', '@PremierDMD', '@AthleticFoodie', 'LinkedIn', '@RyanLochte', 'UANews', '#BearDown', '@NatalieCoughlin', '#CDoM', '@RickyBerens', '@PremierDMD', '@AthleticFoodie', 'LinkedIn', '@TheLeonardLab', 'SportsCenter', '@NatalieCoughlin']\n"
     ]
    }
   ],
   "source": [
    "cc=[]\n",
    "for i in tweetTokens:\n",
    "    if(i[0]==\"@\" or i[0]==\"#\") and checkForCamelCase(i) and countUpperCharacters(i,2) >0 and \"/\" not in i and \"-\" not in i:\n",
    "        cc.append(i)\n",
    "\n",
    "    else:\n",
    "        if checkForCamelCase(i) and countUpperCharacters(i,1) >0 and \"/\" not in i and \"-\" not in i:\n",
    "            cc.append(i)\n",
    "            \n",
    "\n",
    "print(cc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['i', 'Guess']\n",
      "['@', 'India', 'Coast', 'Guard']\n",
      "['#', 'Kerala', 'Floods']\n",
      "['i', 'Guess']\n",
      "['To', 'Wake']\n",
      "['@', 'asawaree', 'Bhide']\n",
      "['#', 'polka', 'Dots']\n",
      "['Hip', 'Happening']\n",
      "['#', 'Burbank']\n",
      "['@', 'De', 'Bruyne', 'Kev']\n",
      "['@', 'Madonna']\n",
      "['#', 'R', 'I', 'P', 'Atal', 'Bihari', 'Vaajpayee']\n",
      "['@', 'sui', 'Dhaagafilm']\n",
      "['i', 'Guess']\n",
      "['i', 'Phone']\n",
      "['@', 'Apple']\n",
      "['@', 'Apple']\n",
      "['i', 'Phone']\n",
      "['#', 'watch', 'E', 'S', 'P', 'N']\n",
      "['Apple', 'T', 'V']\n",
      "['@', 'Apple']\n",
      "['@', 'Tracey', 'Liddle']\n",
      "['@', 'Apple']\n",
      "['@', 'Apple']\n",
      "['i', 'Phone']\n",
      "['#', 'i', 'Phone5', 'C']\n",
      "['@', 'Apple']\n",
      "['i', 'Phone']\n",
      "['@', 'Apple']\n",
      "['i', 'Photo']\n",
      "['i', 'Movie']\n",
      "['i', 'Work']\n",
      "['i', 'Pad']\n",
      "['#', 'i', 'Phone5', 'S']\n",
      "['#', 'Fingerprints', 'Recognitom']\n",
      "['#', 'i', 'Phone']\n",
      "['#', 'Apple']\n",
      "['@', 'Apple']\n",
      "['#', 'Concepts']\n",
      "['Mac', 'Books']\n",
      "['@', 'i', 'Brooklyn', 'B']\n",
      "['@', 'Apple']\n",
      "['@', 'Windows']\n",
      "['@', 'Apple']\n",
      "['@', 'Apple']\n",
      "['#', 'i', 'O', 'S7']\n",
      "['@', 'Lafond66']\n",
      "['@', 'Apple']\n",
      "['i', 'O', 'S']\n",
      "['#', 'i', 'Radio']\n",
      "['@', 'Fast', 'Co', 'Design']\n",
      "['@', 'Apple']\n",
      "['#', 'i', 'Phone']\n",
      "['@', 'i', 'Brooklyn', 'B']\n",
      "['@', 'Apple']\n",
      "['#', 'Fell']\n",
      "['#', 'Working']\n",
      "['@', 'Apple']\n",
      "['@', 'Apple']\n",
      "['@', 'Samsung']\n",
      "['L', 'R', 'W', 'Blog']\n",
      "['#', 'i', 'Phone5s']\n",
      "['@', 'Apple']\n",
      "['Mac', 'Book']\n",
      "['i', 'Phone']\n",
      "['i', 'Phone']\n",
      "['i', 'Phone']\n",
      "['@', 'Apple']\n",
      "['#', 'itunes', 'Festival']\n",
      "['@', 'Apple']\n",
      "['@', 'Microsoft']\n",
      "['@', 'Windows']\n",
      "['@', 'Apple']\n",
      "['@', 'Apple']\n",
      "['#', 'i', 'Phone5', 'S']\n",
      "['#', 'i', 'Phone']\n",
      "['#', 'Apple']\n",
      "['#', 'September20th']\n",
      "['S', 'L', 'Rs']\n",
      "['@', 'Fireand', 'Ice5935']\n",
      "['@', 'Android']\n",
      "['@', 'Apple']\n",
      "['@', 'Apple']\n",
      "['Core', 'Motion']\n",
      "['i', 'Phone']\n",
      "['@', 'Apple']\n",
      "['i', 'Phones']\n",
      "['i', 'Photo']\n",
      "['i', 'Movie']\n",
      "['@', 'Apple']\n",
      "['i', 'Phones']\n",
      "['i', 'Photo']\n",
      "['i', 'Movie']\n",
      "['@', 'Sephora']\n",
      "['@', 'Apple']\n",
      "['i', 'ndustry.', 'Incredible']\n",
      "['@', 'Apple']\n",
      "['@', 'Scale', 'Box', 'App']\n",
      "['@', 'Apple']\n",
      "['@', 'i', 'Tunes', 'Music']\n",
      "['#', 'Apple']\n",
      "['#', 'i', 'Phone']\n",
      "['#', 'i', 'Tunes']\n",
      "['#', 'i', 'Phone5', 'S']\n",
      "['@', 'Apple']\n",
      "['b', 'Phone']\n",
      "['@', 'Beyonce']\n",
      "['@', 'Apple']\n",
      "['i', 'Phone']\n",
      "['@', 'Apple']\n",
      "['#', 'Touch', 'I', 'D']\n",
      "['@', 'Apple']\n",
      "['#', 'courtsideassistappfori', 'O', 'S']\n",
      "['i', 'Phone']\n",
      "['@', 'Apple']\n",
      "['#', 'Iphone']\n",
      "['#', 'Touch']\n",
      "['@', 'Apple']\n",
      "['@', 'Apple']\n",
      "['@', 'The', 'M', 'I', 'X', 'X', 'Radio']\n",
      "['@', 'The', 'Mixx', 'Hangout']\n",
      "['i', 'Phone']\n",
      "['@', 'The', 'Di', 'Massa']\n",
      "['@', 'Samsung']\n",
      "['@', 'Apple']\n",
      "['@', 'Apple']\n",
      "['i', 'Phone']\n",
      "['@', 'Scale', 'Box', 'App']\n",
      "['@', 'Apple']\n",
      "['@', 'i', 'Tunes', 'Music']\n",
      "['#', 'Apple']\n",
      "['#', 'i', 'Phone']\n",
      "['#', 'Piano']\n",
      "['#', 'Music']\n",
      "['#', 'Only', 'Classical']\n",
      "['#', 'Violin']\n",
      "['@', 'Apple']\n",
      "['@', 'Apple']\n",
      "['i', 'O', 'S']\n",
      "['@', 'Stratix']\n",
      "['@', 'Apple']\n",
      "['#', 'Tech']\n",
      "['@', 'Apple']\n",
      "['@', 'Samsung']\n",
      "['@', 'Apple']\n",
      "['@', 'Boeing', 'Airplanes']\n",
      "['@', 'Apple']\n",
      "['@', 'i', 'Brooklyn', 'B']\n",
      "['@', 'Apple']\n",
      "['@', 'Apple']\n",
      "['#', 'Apple']\n",
      "['i', 'Phone']\n",
      "['#', 'i', 'Os']\n",
      "['i', 'Phone']\n",
      "['#', 'Android']\n",
      "['#', 'i', 'Phone']\n",
      "['@', 'Google']\n",
      "['@', 'Apple']\n",
      "['i', 'Phones']\n",
      "['i', 'Phone']\n",
      "['Touch', 'I', 'D']\n",
      "['@', 'Apple']\n",
      "['i', 'Phones']\n",
      "['i', 'Pad']\n",
      "['@', 'Apple']\n",
      "['#', 'i', 'Phone']\n",
      "['@', 'Blake', 'Graham', 'P', 'G', 'A']\n",
      "['@', 'Best', 'Buy']\n",
      "['@', 'Apple']\n",
      "['i', 'Phone']\n",
      "['#', 'California']\n",
      "['I', 'Phone']\n",
      "['@', 'Apple']\n",
      "['#', 'i', 'Phone']\n",
      "['#', 'i', 'O', 'S7']\n",
      "['@', 'Apple']\n",
      "['#', 'Mobile']\n",
      "['#', 'App']\n",
      "['@', 'Apple']\n",
      "['@', 'Apple']\n",
      "['@', 'i', 'More']\n",
      "['@', 'Apple']\n",
      "['#', 'i', 'Pad']\n",
      "['#', 'i', 'Work']\n",
      "['@', 'Apple']\n",
      "['@', 'Apple']\n",
      "['i', 'O', 'S']\n",
      "['@', 'Apple']\n",
      "['#', 'i', 'Phone']\n",
      "['i', 'Phone']\n",
      "['@', 'Nokia']\n",
      "['@', 'Apple']\n",
      "['#', 'Win', 'Phan']\n",
      "['@', 'Jon4', 'Lakers']\n",
      "['@', 'Techno', 'Buffalo']\n",
      "['@', 'Apple']\n",
      "['@', 'E', 'T', 'Canada']\n",
      "['@', 'Clusocluso']\n",
      "['@', 'Apple']\n",
      "['@', 'Burberry']\n",
      "['#', 'Digitallyperfect']\n",
      "['#', 'Tech']\n",
      "['@', 'Apple']\n",
      "['#', 'i', 'Phone5', 'C']\n",
      "['i', 'O', 'S']\n",
      "['@', 'Apple']\n",
      "['@', 'Apple']\n",
      "['#', 'Innovation']\n",
      "['@', 'J', 'M', 'L', 'Colley']\n",
      "['@', 'Apple']\n",
      "['@', 'The', 'Espin', 'Alien']\n",
      "['@', 'i', 'Brooklyn', 'B']\n",
      "['@', 'Apple']\n",
      "['i', 'Phone']\n",
      "['#', 'Iphone5c']\n",
      "['@', 'highly', 'H', 'I', 'G', 'Htori']\n",
      "['@', 'Apple']\n",
      "['#', 'Apple', 'Freak']\n",
      "['@', 'Apple']\n",
      "['@', 'Apple']\n",
      "['i', 'Phone']\n",
      "['i', 'Phone']\n",
      "['i', 'O', 'S']\n",
      "['#', 'i', 'Phone']\n",
      "['i', 'Phone']\n",
      "['@', '7even', 'Starz']\n",
      "['@', 'Apple']\n",
      "['#', 'Jony', 'Ive']\n",
      "['#', 'i', 'Phone5c']\n",
      "['@', 'Apple']\n",
      "['@', 'O', 'I', 'T', 'Help', 'Desk']\n",
      "['@', 'Apple']\n",
      "['#', 'i', 'Phone5', 'C']\n",
      "['#', 'Pink']\n",
      "['#', 'Apple', 'Picking']\n",
      "['@', 'Sprint']\n",
      "['@', 'Samsung']\n",
      "['@', 'Apple']\n",
      "['@', 'Miss', 'Philly2013']\n",
      "['@', 'Apple']\n",
      "['#', 'i', 'O', 'S7']\n",
      "['@', 'Apple']\n",
      "['i', 'Phones']\n",
      "['@', '7even', 'Starz']\n",
      "['@', 'Apple']\n",
      "['@', 'Apple']\n",
      "['i', 'Phone']\n",
      "['#', 'India']\n",
      "['#', 'e', 'Bay', 'Check']\n",
      "['@', 'e', 'Bay', 'India']\n",
      "['#', 'e', 'Bay', 'Check']\n",
      "['@', 'Apple']\n",
      "['i', 'Phone']\n",
      "['i', 'Pad']\n",
      "['@', 'Om']\n",
      "['@', 'Apple']\n",
      "['i', 'Phones']\n",
      "['#', 'i', 'Beacons']\n",
      "['#', 'i', 'O', 'S']\n",
      "['#', 'i', 'Phone']\n",
      "['i', 'Phones']\n",
      "['@', 'Apple']\n",
      "['@', 'i', 'Brooklyn', 'B']\n",
      "['@', 'Apple']\n",
      "['@', 'Ellie', 'Dash']\n",
      "['@', 'Dave', 'Lee', 'B', 'B', 'C']\n",
      "['@', 'Lexxxzis']\n",
      "['@', 'Super', 'Cool', 'Cube']\n",
      "['@', 'Molecular', 'Love']\n",
      "['@', 'Ryan', 'Lochte']\n",
      "['U', 'A', 'News']\n",
      "['#', 'Bear', 'Down']\n",
      "['@', 'Natalie', 'Coughlin']\n",
      "['#', 'C', 'Do', 'M']\n",
      "['@', 'Ricky', 'Berens']\n",
      "['@', 'Premier', 'D', 'M', 'D']\n",
      "['@', 'Athletic', 'Foodie']\n",
      "['Linked', 'In']\n",
      "['@', 'Ryan', 'Lochte']\n",
      "['U', 'A', 'News']\n",
      "['#', 'Bear', 'Down']\n",
      "['@', 'Natalie', 'Coughlin']\n",
      "['#', 'C', 'Do', 'M']\n",
      "['@', 'Ricky', 'Berens']\n",
      "['@', 'Premier', 'D', 'M', 'D']\n",
      "['@', 'Athletic', 'Foodie']\n",
      "['Linked', 'In']\n",
      "['@', 'The', 'Leonard', 'Lab']\n",
      "['Sports', 'Center']\n",
      "['@', 'Natalie', 'Coughlin']\n"
     ]
    }
   ],
   "source": [
    "for i in cc:\n",
    "    print(camel_case_split(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
