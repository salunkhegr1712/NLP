{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import the basic nltk package \n",
    "import nltk\n",
    "import pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[('The', 'DET'), ('Fulton', 'NOUN'), ('County', 'NOUN'), ('Grand', 'ADJ'), ('Jury', 'NOUN'), ('said', 'VERB'), ('Friday', 'NOUN'), ('an', 'DET'), ('investigation', 'NOUN'), ('of', 'ADP'), (\"Atlanta's\", 'NOUN'), ('recent', 'ADJ'), ('primary', 'NOUN'), ('election', 'NOUN'), ('produced', 'VERB'), ('``', '.'), ('no', 'DET'), ('evidence', 'NOUN'), (\"''\", '.'), ('that', 'ADP'), ('any', 'DET'), ('irregularities', 'NOUN'), ('took', 'VERB'), ('place', 'NOUN'), ('.', '.')], [('The', 'DET'), ('jury', 'NOUN'), ('further', 'ADV'), ('said', 'VERB'), ('in', 'ADP'), ('term-end', 'NOUN'), ('presentments', 'NOUN'), ('that', 'ADP'), ('the', 'DET'), ('City', 'NOUN'), ('Executive', 'ADJ'), ('Committee', 'NOUN'), (',', '.'), ('which', 'DET'), ('had', 'VERB'), ('over-all', 'ADJ'), ('charge', 'NOUN'), ('of', 'ADP'), ('the', 'DET'), ('election', 'NOUN'), (',', '.'), ('``', '.'), ('deserves', 'VERB'), ('the', 'DET'), ('praise', 'NOUN'), ('and', 'CONJ'), ('thanks', 'NOUN'), ('of', 'ADP'), ('the', 'DET'), ('City', 'NOUN'), ('of', 'ADP'), ('Atlanta', 'NOUN'), (\"''\", '.'), ('for', 'ADP'), ('the', 'DET'), ('manner', 'NOUN'), ('in', 'ADP'), ('which', 'DET'), ('the', 'DET'), ('election', 'NOUN'), ('was', 'VERB'), ('conducted', 'VERB'), ('.', '.')], ...]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.corpus import brown\n",
    "words=brown.tagged_sents(tagset='universal')\n",
    "words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lets create a object which is able to store the info \n",
    "class WordEmition:\n",
    "    def __init__(self, name): \n",
    "        self.name = name \n",
    "    def newAttr(self, attr):\n",
    "\t    setattr(self, attr, attr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "57340\n"
     ]
    }
   ],
   "source": [
    "# pos tags of the perticular word \n",
    "# this is code for finding the transition probabilities of brwon corpus  words \n",
    "# from nltk.corpus import brown\n",
    "# words=brown.tagged_sents(tagset='universal')\n",
    "\n",
    "print(len(words))\n",
    "pos=[]\n",
    "keys=[]\n",
    "for i in words:\n",
    "    keys.append(\"PHI\")\n",
    "    pos.append(\"PHI\")\n",
    "    for j in i:\n",
    "        \n",
    "        keys.append(j[0])\n",
    "        pos.append(j[1])\n",
    "\n",
    "# print(keys)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['.',\n",
       " 'ADJ',\n",
       " 'ADP',\n",
       " 'ADV',\n",
       " 'CONJ',\n",
       " 'DET',\n",
       " 'NOUN',\n",
       " 'NUM',\n",
       " 'PHI',\n",
       " 'PRON',\n",
       " 'PRT',\n",
       " 'VERB',\n",
       " 'X']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "uniqueTags=list(set(pos))\n",
    "uniqueTags.sort()\n",
    "uniqueTags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# so we are going find and write the code which can give us the transition table between pos \n",
    "def transitionVal(a,b):\n",
    "    k=0\n",
    "    s=0\n",
    "    for i in range(len(keys)):\n",
    "        if(keys[i]==\"PHI\"):\n",
    "            pass\n",
    "        else:\n",
    "            if(pos[i]==b and pos[i-1]==a):\n",
    "                k+=1\n",
    "                s+=1\n",
    "            elif(pos[i]==b):\n",
    "                s+=1\n",
    "\n",
    "    if s==0:\n",
    "        return 0\n",
    "    return k/s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transitionVal(\"ADJ\",\"PHI\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transitionTable():\n",
    "    f=len(uniqueTags)\n",
    "    matrix=[]\n",
    "\n",
    "    for i in uniqueTags:\n",
    "        m=[]\n",
    "        with open(\"111903074_A5_TTP.txt\",\"a+\") as f:\n",
    "            f.write(f\"\\nTag transitions from {i} \\n\")\n",
    "            for j in uniqueTags:\n",
    "                z=transitionVal(i,j)\n",
    "                f.write(f\" {i} ==> {j} : {z} \\n\")\n",
    "                m.append(z)\n",
    "            matrix.append(m)    \n",
    "    return matrix\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.107146</td>\n",
       "      <td>0.050895</td>\n",
       "      <td>0.066487</td>\n",
       "      <td>0.114316</td>\n",
       "      <td>0.268381</td>\n",
       "      <td>0.073004</td>\n",
       "      <td>0.044368</td>\n",
       "      <td>0.119672</td>\n",
       "      <td>0</td>\n",
       "      <td>0.138606</td>\n",
       "      <td>0.090684</td>\n",
       "      <td>0.061904</td>\n",
       "      <td>0.134199</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.056951</td>\n",
       "      <td>0.056915</td>\n",
       "      <td>0.051165</td>\n",
       "      <td>0.014403</td>\n",
       "      <td>0.082488</td>\n",
       "      <td>0.003569</td>\n",
       "      <td>0.198307</td>\n",
       "      <td>0.039263</td>\n",
       "      <td>0</td>\n",
       "      <td>0.006486</td>\n",
       "      <td>0.054108</td>\n",
       "      <td>0.008005</td>\n",
       "      <td>0.030303</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.009562</td>\n",
       "      <td>0.142867</td>\n",
       "      <td>0.020302</td>\n",
       "      <td>0.039901</td>\n",
       "      <td>0.007156</td>\n",
       "      <td>0.481393</td>\n",
       "      <td>0.135779</td>\n",
       "      <td>0.292927</td>\n",
       "      <td>0</td>\n",
       "      <td>0.204768</td>\n",
       "      <td>0.069127</td>\n",
       "      <td>0.032651</td>\n",
       "      <td>0.048341</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.064853</td>\n",
       "      <td>0.091566</td>\n",
       "      <td>0.055117</td>\n",
       "      <td>0.096837</td>\n",
       "      <td>0.025530</td>\n",
       "      <td>0.030186</td>\n",
       "      <td>0.006699</td>\n",
       "      <td>0.050222</td>\n",
       "      <td>0</td>\n",
       "      <td>0.055114</td>\n",
       "      <td>0.054075</td>\n",
       "      <td>0.073970</td>\n",
       "      <td>0.003608</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.005381</td>\n",
       "      <td>0.051027</td>\n",
       "      <td>0.019314</td>\n",
       "      <td>0.061950</td>\n",
       "      <td>0.000262</td>\n",
       "      <td>0.042126</td>\n",
       "      <td>0.033728</td>\n",
       "      <td>0.047936</td>\n",
       "      <td>0</td>\n",
       "      <td>0.052276</td>\n",
       "      <td>0.032150</td>\n",
       "      <td>0.040793</td>\n",
       "      <td>0.015152</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.011866</td>\n",
       "      <td>0.392327</td>\n",
       "      <td>0.008586</td>\n",
       "      <td>0.042675</td>\n",
       "      <td>0.002307</td>\n",
       "      <td>0.005904</td>\n",
       "      <td>0.311506</td>\n",
       "      <td>0.089956</td>\n",
       "      <td>0</td>\n",
       "      <td>0.027527</td>\n",
       "      <td>0.009219</td>\n",
       "      <td>0.048487</td>\n",
       "      <td>0.139971</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.529807</td>\n",
       "      <td>0.042439</td>\n",
       "      <td>0.465061</td>\n",
       "      <td>0.129305</td>\n",
       "      <td>0.431103</td>\n",
       "      <td>0.031164</td>\n",
       "      <td>0.149312</td>\n",
       "      <td>0.149388</td>\n",
       "      <td>0</td>\n",
       "      <td>0.110674</td>\n",
       "      <td>0.164773</td>\n",
       "      <td>0.239469</td>\n",
       "      <td>0.066378</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.027290</td>\n",
       "      <td>0.010535</td>\n",
       "      <td>0.013470</td>\n",
       "      <td>0.005388</td>\n",
       "      <td>0.014941</td>\n",
       "      <td>0.001423</td>\n",
       "      <td>0.020537</td>\n",
       "      <td>0.021716</td>\n",
       "      <td>0</td>\n",
       "      <td>0.002554</td>\n",
       "      <td>0.002648</td>\n",
       "      <td>0.003705</td>\n",
       "      <td>0.002165</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.034554</td>\n",
       "      <td>0.023519</td>\n",
       "      <td>0.048658</td>\n",
       "      <td>0.093138</td>\n",
       "      <td>0.073838</td>\n",
       "      <td>0.089316</td>\n",
       "      <td>0.029369</td>\n",
       "      <td>0.064811</td>\n",
       "      <td>0</td>\n",
       "      <td>0.185612</td>\n",
       "      <td>0.070502</td>\n",
       "      <td>0.014161</td>\n",
       "      <td>0.021645</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.034669</td>\n",
       "      <td>0.005590</td>\n",
       "      <td>0.019017</td>\n",
       "      <td>0.047387</td>\n",
       "      <td>0.014731</td>\n",
       "      <td>0.006306</td>\n",
       "      <td>0.001586</td>\n",
       "      <td>0.003294</td>\n",
       "      <td>0</td>\n",
       "      <td>0.008189</td>\n",
       "      <td>0.039291</td>\n",
       "      <td>0.190632</td>\n",
       "      <td>0.000722</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.015505</td>\n",
       "      <td>0.006737</td>\n",
       "      <td>0.018692</td>\n",
       "      <td>0.019186</td>\n",
       "      <td>0.009541</td>\n",
       "      <td>0.018187</td>\n",
       "      <td>0.003869</td>\n",
       "      <td>0.010219</td>\n",
       "      <td>0</td>\n",
       "      <td>0.004135</td>\n",
       "      <td>0.011231</td>\n",
       "      <td>0.101603</td>\n",
       "      <td>0.001443</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.099841</td>\n",
       "      <td>0.125536</td>\n",
       "      <td>0.213621</td>\n",
       "      <td>0.335337</td>\n",
       "      <td>0.068884</td>\n",
       "      <td>0.217371</td>\n",
       "      <td>0.064665</td>\n",
       "      <td>0.110528</td>\n",
       "      <td>0</td>\n",
       "      <td>0.203876</td>\n",
       "      <td>0.401857</td>\n",
       "      <td>0.184224</td>\n",
       "      <td>0.024531</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.002575</td>\n",
       "      <td>0.000048</td>\n",
       "      <td>0.000511</td>\n",
       "      <td>0.000178</td>\n",
       "      <td>0.000839</td>\n",
       "      <td>0.000051</td>\n",
       "      <td>0.000276</td>\n",
       "      <td>0.000067</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000182</td>\n",
       "      <td>0.000335</td>\n",
       "      <td>0.000394</td>\n",
       "      <td>0.511544</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          0         1         2         3         4         5         6   \\\n",
       "0   0.107146  0.050895  0.066487  0.114316  0.268381  0.073004  0.044368   \n",
       "1   0.056951  0.056915  0.051165  0.014403  0.082488  0.003569  0.198307   \n",
       "2   0.009562  0.142867  0.020302  0.039901  0.007156  0.481393  0.135779   \n",
       "3   0.064853  0.091566  0.055117  0.096837  0.025530  0.030186  0.006699   \n",
       "4   0.005381  0.051027  0.019314  0.061950  0.000262  0.042126  0.033728   \n",
       "5   0.011866  0.392327  0.008586  0.042675  0.002307  0.005904  0.311506   \n",
       "6   0.529807  0.042439  0.465061  0.129305  0.431103  0.031164  0.149312   \n",
       "7   0.027290  0.010535  0.013470  0.005388  0.014941  0.001423  0.020537   \n",
       "8   0.034554  0.023519  0.048658  0.093138  0.073838  0.089316  0.029369   \n",
       "9   0.034669  0.005590  0.019017  0.047387  0.014731  0.006306  0.001586   \n",
       "10  0.015505  0.006737  0.018692  0.019186  0.009541  0.018187  0.003869   \n",
       "11  0.099841  0.125536  0.213621  0.335337  0.068884  0.217371  0.064665   \n",
       "12  0.002575  0.000048  0.000511  0.000178  0.000839  0.000051  0.000276   \n",
       "\n",
       "          7   8         9         10        11        12  \n",
       "0   0.119672   0  0.138606  0.090684  0.061904  0.134199  \n",
       "1   0.039263   0  0.006486  0.054108  0.008005  0.030303  \n",
       "2   0.292927   0  0.204768  0.069127  0.032651  0.048341  \n",
       "3   0.050222   0  0.055114  0.054075  0.073970  0.003608  \n",
       "4   0.047936   0  0.052276  0.032150  0.040793  0.015152  \n",
       "5   0.089956   0  0.027527  0.009219  0.048487  0.139971  \n",
       "6   0.149388   0  0.110674  0.164773  0.239469  0.066378  \n",
       "7   0.021716   0  0.002554  0.002648  0.003705  0.002165  \n",
       "8   0.064811   0  0.185612  0.070502  0.014161  0.021645  \n",
       "9   0.003294   0  0.008189  0.039291  0.190632  0.000722  \n",
       "10  0.010219   0  0.004135  0.011231  0.101603  0.001443  \n",
       "11  0.110528   0  0.203876  0.401857  0.184224  0.024531  \n",
       "12  0.000067   0  0.000182  0.000335  0.000394  0.511544  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z=transitionTable()\n",
    "df=pandas.DataFrame(z)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.029369497528650954"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[uniqueTags.index(\"NOUN\")][uniqueTags.index(\"PHI\")]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# transitionVal()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import nltk\n",
    "# from nltk.corpus import PlaintextCorpusReader\n",
    "# corpus_root = './'\n",
    "# newcorpus = PlaintextCorpusReader(corpus_root, '.*')\n",
    "# words=newcorpus.sents('inputText.txt')\n",
    "# kk=[]\n",
    "# for i in words:\n",
    "#     kk.append(pos_tag(i,tagset=\"universal\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(len(kk))\n",
    "# pos=[]\n",
    "# keys=[]\n",
    "# for i in kk:\n",
    "#     keys.append(\"PHI\")\n",
    "#     pos.append(\"PHI\")\n",
    "#     for j in i:\n",
    "        \n",
    "#         keys.append(j[0])\n",
    "#         pos.append(j[1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# so this is probality for the emision for a word in corpus to have perticular tagset \n",
    "# with this code we write the emitionProbability into the code \n",
    "\n",
    "def emitionProbability(word):\n",
    "    ml=[i for i,val in enumerate(keys) if val==word]\n",
    "    # print(ml)\n",
    "    kk=[]\n",
    "    for i in ml:\n",
    "        kk.append(pos[i])\n",
    "    gk=set(kk)\n",
    "    p=WordEmition(name=word)\n",
    "    for i in gk: \n",
    "        p.newAttr(i)\n",
    "        setattr(p,i,kk.count(i)/len(kk))\n",
    "\n",
    "    # with open(\"WEP1.txt\",\"a+\") as f:\n",
    "        \n",
    "    #     f.write(str(vars(p)))\n",
    "    #     f.write('\\n')\n",
    "    return p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# so we have to find emission prob of two words\n",
    "\n",
    "def emmisionVal(b,tag):\n",
    "    \n",
    "    ml=[i for i,val in enumerate(keys) if val==b]\n",
    "    # print(ml)\n",
    "    kk=[]\n",
    "    for i in ml:\n",
    "        kk.append(pos[i])\n",
    "    gk=set(kk)\n",
    "    p=WordEmition(name=b)\n",
    "    for i in gk: \n",
    "        p.newAttr(i)\n",
    "        setattr(p,i,kk.count(i)/len(kk))\n",
    "    \n",
    "    return p.__getattribute__(tag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# emmisionVal(\"do\",\"PRT\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def emmisionList(b):\n",
    "    \n",
    "    ml=[i for i,val in enumerate(keys) if val==b]\n",
    "    # print(ml)\n",
    "    kk=[]\n",
    "    for i in ml:\n",
    "        kk.append(pos[i])\n",
    "    gk=set(kk)\n",
    "    p=WordEmition(name=b)\n",
    "    for i in gk: \n",
    "        p.newAttr(i)\n",
    "        setattr(p,i,kk.count(i)/len(kk))\n",
    "    \n",
    "    return p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk import word_tokenize\n",
    "f=open(\"inputText.txt\",\"r\")\n",
    "f=f.read()\n",
    "f=word_tokenize(f)\n",
    "# print(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # print(f)\n",
    "# with open(\"WEP.txt\",\"a\") as g:\n",
    "#     for i in f:\n",
    "#         p=emmisionVal(i)\n",
    "#         j=vars(p)\n",
    "#         g.write(\"{\"+'; '.join(\"%s: %s\" % item for item in j.items())+\"}\")\n",
    "#         g.write(\"\\n\")\n",
    "#     # this is code for printing the data inside the class \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk import sent_tokenize\n",
    "import itertools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def combi(a,b):\n",
    "    g=list(itertools.product(a,b))\n",
    "    k=[]\n",
    "    for i in range(len(g)):\n",
    "        l=list(g[i][0])\n",
    "        l.append(g[i][1])\n",
    "        k.append(l)\n",
    "    return k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['hello'], [['hi', 'dd']]]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combi([\"\"],[\"hello\",[\"hi\",\"dd\"]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# find prob for the a combination \n",
    "l=['PHI', 'PRON', 'VERB', 'X', 'ADJ', 'PRT', 'X', 'ADJ', 'VERB', '.']\n",
    "\n",
    "def prob(s,l):\n",
    "    # print(l)\n",
    "    prob=1\n",
    "    s=word_tokenize(s)\n",
    "    for i in range(1,len(l)):\n",
    "        if(prob==0):\n",
    "            return 0\n",
    "        e=emmisionVal(s[i],l[i])\n",
    "        t=df[uniqueTags.index(l[i])][uniqueTags.index(l[i-1])]\n",
    "\n",
    "        prob*=e*t\n",
    "    return prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "prob() missing 1 required positional argument: 'l'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [24], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m prob(\u001b[39m\"\u001b[39;49m\u001b[39mhello to\u001b[39;49m\u001b[39m\"\u001b[39;49m)\n",
      "\u001b[0;31mTypeError\u001b[0m: prob() missing 1 required positional argument: 'l'"
     ]
    }
   ],
   "source": [
    "prob(\"hello to\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def intm(s):\n",
    "    s=\"PHI \"+s\n",
    "    g=word_tokenize(s)\n",
    "    b=[]\n",
    "    for i in g:\n",
    "        p=emmisionList(i)\n",
    "        del p.name\n",
    "        # b.append(getmembers()\n",
    "        # following code will help us to list all attribute inside the string \n",
    "        b.append([k for k, p in p.__dict__.items() if not str(hex(id(p))) in str(p)])\n",
    "    # print(b)\n",
    "    k=[]\n",
    "    print(b)\n",
    "    # print(b)\n",
    "    l=[\"\"]\n",
    "    for i in range(len(b)):\n",
    "        l=combi(l,b[i])\n",
    "        # find all formations \n",
    "    # so we get all possible combinations here so we have to find the value max \n",
    "    return l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['PHI'], ['PRT'], ['ADV', 'ADP', 'PRT', 'NOUN', 'X'], ['VERB'], ['ADV'], ['ADV', 'ADP', 'PRT', 'NOUN', 'X']]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[['PHI', 'PRT', 'ADV', 'VERB', 'ADV', 'ADV'],\n",
       " ['PHI', 'PRT', 'ADV', 'VERB', 'ADV', 'ADP'],\n",
       " ['PHI', 'PRT', 'ADV', 'VERB', 'ADV', 'PRT'],\n",
       " ['PHI', 'PRT', 'ADV', 'VERB', 'ADV', 'NOUN'],\n",
       " ['PHI', 'PRT', 'ADV', 'VERB', 'ADV', 'X'],\n",
       " ['PHI', 'PRT', 'ADP', 'VERB', 'ADV', 'ADV'],\n",
       " ['PHI', 'PRT', 'ADP', 'VERB', 'ADV', 'ADP'],\n",
       " ['PHI', 'PRT', 'ADP', 'VERB', 'ADV', 'PRT'],\n",
       " ['PHI', 'PRT', 'ADP', 'VERB', 'ADV', 'NOUN'],\n",
       " ['PHI', 'PRT', 'ADP', 'VERB', 'ADV', 'X'],\n",
       " ['PHI', 'PRT', 'PRT', 'VERB', 'ADV', 'ADV'],\n",
       " ['PHI', 'PRT', 'PRT', 'VERB', 'ADV', 'ADP'],\n",
       " ['PHI', 'PRT', 'PRT', 'VERB', 'ADV', 'PRT'],\n",
       " ['PHI', 'PRT', 'PRT', 'VERB', 'ADV', 'NOUN'],\n",
       " ['PHI', 'PRT', 'PRT', 'VERB', 'ADV', 'X'],\n",
       " ['PHI', 'PRT', 'NOUN', 'VERB', 'ADV', 'ADV'],\n",
       " ['PHI', 'PRT', 'NOUN', 'VERB', 'ADV', 'ADP'],\n",
       " ['PHI', 'PRT', 'NOUN', 'VERB', 'ADV', 'PRT'],\n",
       " ['PHI', 'PRT', 'NOUN', 'VERB', 'ADV', 'NOUN'],\n",
       " ['PHI', 'PRT', 'NOUN', 'VERB', 'ADV', 'X'],\n",
       " ['PHI', 'PRT', 'X', 'VERB', 'ADV', 'ADV'],\n",
       " ['PHI', 'PRT', 'X', 'VERB', 'ADV', 'ADP'],\n",
       " ['PHI', 'PRT', 'X', 'VERB', 'ADV', 'PRT'],\n",
       " ['PHI', 'PRT', 'X', 'VERB', 'ADV', 'NOUN'],\n",
       " ['PHI', 'PRT', 'X', 'VERB', 'ADV', 'X']]"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "intm(\"hello to am here to\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# so now we are ready with the algo now we have just small task to deal with and that is we have to find out the\n",
    "# probability value of given sentense with the help of the emmision probability and transition Probability\n",
    "\n",
    "def viterbiAlgo(s,l):\n",
    "    s=\"PHI \"+s\n",
    "# lets Assign letters to each of the all types \n",
    "    # emmisionVal *transitionVal\n",
    "    # print(s)\n",
    "    m=0\n",
    "    zz=[]\n",
    "    for i in l:\n",
    "        \n",
    "        val=prob(s,i)\n",
    "\n",
    "        if val>m:\n",
    "            m=val\n",
    "            zz=i\n",
    "\n",
    "    return zz[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s=\"to be or falcon it is\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main(s):\n",
    "    l=intm(s)\n",
    "    print(word_tokenize(s))\n",
    "    print(viterbiAlgo(s,l))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['PHI'], ['ADV', 'ADP', 'PRT', 'NOUN', 'X'], ['VERB', 'X'], ['X', 'CONJ'], ['NOUN'], ['PRT', 'PRON'], ['VERB', 'X']]\n",
      "['to', 'be', 'or', 'falcon', 'it', 'is']\n",
      "['PRT', 'VERB', 'CONJ', 'NOUN', 'PRON', 'VERB']\n"
     ]
    }
   ],
   "source": [
    "\n",
    "main(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['PHI'], ['PRT'], ['.'], ['ADV'], ['VERB'], ['PRON'], ['X', '.'], ['VERB'], ['PRON'], ['PRT'], ['PRT', 'ADV']]\n",
      "['hello', '!', 'how', 'are', 'you', '?', 'are', 'you', 'hello', 'there']\n",
      "['PRT', '.', 'ADV', 'VERB', 'PRON', '.', 'VERB', 'PRON', 'PRT', 'PRT']\n"
     ]
    }
   ],
   "source": [
    "main(\"hello! how are you? are you hello there\")\n",
    "        "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.6 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "e7370f93d1d0cde622a1f8e1c04877d8463912d04d973331ad4851f04de6915a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
